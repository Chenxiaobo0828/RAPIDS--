{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ab6f5d",
   "metadata": {},
   "source": [
    "## ------------------------------------- XGBoost - SHAP ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10508b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -------------------------------------------\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(action='ignore')\n",
    "zh = DataFrame(np.arange(1).reshape(1,1))\n",
    "\n",
    "cohort = 4\n",
    "dataDir = r'datapath'\n",
    "train_filename = '/train.csv'\n",
    "test_filename = '/test.csv'\n",
    "val_filename = '/val.csv'\n",
    "val2_filename = '/val.csv'\n",
    "\n",
    "## --------------------------------------------\n",
    "train_data = pd.read_csv(dataDir + train_filename)\n",
    "print(train_data.iloc[0:3, 0:5])\n",
    "print('\\n', train_data.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a37be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc =2\n",
    "x_train = train_data.iloc[:,cc:]\n",
    "y_train = train_data.iloc[:,1]    \n",
    "ratio = 1- sum(y_train == 1) / len(y_train) \n",
    "print('\\n', round(ratio, 3))\n",
    "print(x_train.iloc[0:1, 0:3], '\\n')\n",
    "print('\\n', x_train.shape)\n",
    "\n",
    "## ---------------------------------------\n",
    "test_data = pd.read_csv(dataDir + test_filename)\n",
    "x_test = test_data.iloc[:,cc:]\n",
    "y_test = test_data.iloc[:,1] \n",
    "print(x_test.iloc[0:1, 0:3], '\\n')\n",
    "print('\\n', x_test.shape)\n",
    "\n",
    "## --------------------------------------\n",
    "val_data = pd.read_csv(dataDir + val_filename)\n",
    "x_val = val_data.iloc[:,cc:]\n",
    "y_val = val_data.iloc[:,1] \n",
    "print(x_val.iloc[0:1, 0:3])\n",
    "print('\\n', x_val.shape)\n",
    "\n",
    "## ---------------------------------------\n",
    "val2_data = pd.read_csv(dataDir + val2_filename)\n",
    "x_val2 = val2_data.iloc[:,cc:]\n",
    "y_val2 = val2_data.iloc[:,1] \n",
    "print(x_val2.iloc[0:1, 0:3])\n",
    "print('\\n', x_val2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ede150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "import time\n",
    "format_date = time.strftime(\"Model_%Y-%m-%d_%H.%M\", time.localtime(time.time()))\n",
    "print(dataDir + '/' + format_date)\n",
    "\n",
    "import os\n",
    "os.mkdir(dataDir + '/' + format_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a9ee5",
   "metadata": {},
   "source": [
    "# ------------------------------------- XGBoost  ----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b5cb4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = 'Model_Xgboost'\n",
    "best_score = 0\n",
    "print('Baseline:', best_score)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "for n_estimators in range(3, 16, 3):\n",
    "    for max_depth in range(1, 4, 1):\n",
    "        for colsample_bytree in [0.5]:\n",
    "            for subsample in [0.6, 0.4]:\n",
    "                for child in [1]:\n",
    "                    model_forest = XGBClassifier(max_depth=max_depth, colsample_bytree=colsample_bytree, n_estimators=n_estimators, subsample=subsample, booster='gbtree',\n",
    "                                                 child=child, gpu_id = 0, n_jobs=-1, random_state=60).fit(x_train, y_train)\n",
    "                    from sklearn import metrics\n",
    "                    from sklearn.metrics import roc_auc_score\n",
    "                    train_score = round(metrics.roc_auc_score(y_train, model_forest.predict_proba(x_train)[:,1]), 3)\n",
    "                    test_score = round(metrics.roc_auc_score(y_test, model_forest.predict_proba(x_test)[:,1]), 3)\n",
    "                    val_score = round(metrics.roc_auc_score(y_val, model_forest.predict_proba(x_val)[:,1]), 3)\n",
    "                    val2_score = round(metrics.roc_auc_score(y_val2, model_forest.predict_proba(x_val2)[:,1]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e6b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "print(dataDir + '\\\\' + format_date + '\\\\' + '  model_Xgboost.pkl')\n",
    "joblib.dump(best_model, dataDir + '\\\\' + format_date + '\\\\' +'Model_Xgboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------forest--------------------------------------\n",
    "import joblib\n",
    "format_date = 'Model_2023-06-14_23.30'\n",
    "print(dataDir + '\\\\' + format_date + '\\\\' + '  Model_Xgboost.pkl')\n",
    "joblib.dump(best_model, dataDir + '\\\\' + format_date + '\\\\' +'Model_Xgboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_file = dataDir + '\\\\' + format_date + '\\\\' + model + '.pkl'\n",
    "best_model = joblib.load(model_file)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(); plt.close(); plt.close(); plt.close()\n",
    "import seaborn as sns\n",
    "f_importance = best_model.feature_importances_\n",
    "head_lst = x_train.columns.values.tolist()\n",
    "print(head_lst)\n",
    "print(f_importance)\n",
    "df_importance = pd.DataFrame({'head':head_lst,'importance':f_importance})\n",
    "df_importance = df_importance.sort_values(by=['importance'],ascending=False) \n",
    "\n",
    "df_p_i = df_importance[df_importance['importance']>0.00000]\n",
    "myfig = plt.gcf()\n",
    "plt.gcf().set_size_inches(4,4)\n",
    "sns.barplot(x='importance',y='head',data=df_p_i)\n",
    "plt.xlabel('Feature importance of ' + model, fontsize=10)\n",
    "plt.ylabel('')\n",
    "myfig.savefig(dataDir + '\\\\' + format_date + '\\\\' + '1.Importance.pdf',dpi=350,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a68d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "def model_perform(x, y, savename, cutoff):\n",
    "    y_proba = best_model.predict_proba(x)[:, 1]\n",
    "    print(y_proba)\n",
    "    if cutoff == 'Train':\n",
    "        fpr, tpr, threshold = metrics.roc_curve(y, y_proba, pos_label=1)\n",
    "        cutoff = threshold[np.argmax(tpr-fpr)]\n",
    "    y_predict = np.int64(y_proba >= cutoff)\n",
    "    \n",
    "    Matrix = metrics.confusion_matrix(y, y_predict)\n",
    "    \n",
    "    print('\\n', Matrix)\n",
    "    print('Accuracy   ',  \"%.3f\" % ((Matrix[1,1]+Matrix[0,0])/sum(sum(Matrix))))\n",
    "    print('Sensitivity',  \"%.3f\" % (Matrix[1,1]/(Matrix[1,1]+Matrix[1,0])))\n",
    "    print('Specificity',  \"%.3f\" % (Matrix[0,0]/(Matrix[0,1]+Matrix[0,0])))\n",
    "    print('PPV        ',  \"%.3f\" % (Matrix[1,1]/(Matrix[1,1]+Matrix[0,1])))\n",
    "    print('NPV        ',  \"%.3f\" % (Matrix[0,0]/(Matrix[0,0]+Matrix[1,0])))\n",
    "    print('F1 score   ',  \"%.3f\" % (2/(2+(Matrix[1,0]+Matrix[0,1])/Matrix[1,1])))\n",
    "    print('G-mean     ',  \"%.3f\" % pow((Matrix[1,1]/(Matrix[1,1]+Matrix[0,1]))*(Matrix[0,0]/(Matrix[0,1]+Matrix[0,0])), 0.5))\n",
    "    print('AUC Score  ',  \"%.3f\" % (metrics.roc_auc_score(y, y_proba)))\n",
    "    print('\\n')\n",
    "    \n",
    "    df = x\n",
    "    df['label'] = y\n",
    "    df['probably'] = y_proba\n",
    "    df.to_csv(dataDir + '\\\\' + format_date + '\\\\' + savename, encoding='gbk', index=False)\n",
    "    return cutoff\n",
    "\n",
    "cutoff = model_perform(train_data.iloc[:,cc:], y_train, model + '_train_predict.csv', 'Train')\n",
    "model_perform(test_data.iloc[:,cc:], y_test, model + '_test_predict.csv', cutoff)\n",
    "model_perform(val_data.iloc[:,cc:], y_val, model + '_val_predict.csv', cutoff)\n",
    "model_perform(val2_data.iloc[:,cc:], y_val2, model + '_val2_predict.csv', cutoff)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5fb37",
   "metadata": {},
   "source": [
    "# ------------------------------ SHAP -----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a430d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer(x_train)\n",
    "sum_shap_values = explainer.shap_values(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bc9cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------- SHAP Beeswarm plot ----------------------------\n",
    "Max_display = df_p_i.shape[0]\n",
    "import matplotlib.pyplot as plt\n",
    "def SHAP_bar(x, Max_display, filename, width, height):\n",
    "    myfig = plt.gcf()\n",
    "    sum_shap_values = explainer.shap_values(x)\n",
    "    shap.summary_plot(sum_shap_values, x, max_display=Max_display)\n",
    "    myfig.savefig(dataDir + '\\\\' + format_date + '\\\\' + filename + ' .pdf', dpi=300, bbox_inches = 'tight')\n",
    "    myfig.savefig(dataDir + '\\\\' + format_date + '\\\\' + filename + '.tiff', dpi=300, bbox_inches = 'tight')\n",
    "\n",
    "SHAP_bar(x_train, Max_display, '2. Beeswarm_train', 2, 4)\n",
    "SHAP_bar(x_test, Max_display,  '2. Beeswarm_test', 2, 4)\n",
    "SHAP_bar(x_val,  Max_display,  '2. Beeswarm_val', 6, 4)\n",
    "SHAP_bar(x_val2, Max_display,  '2. Beeswarm_val2', 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f845091",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train; y = y_train; data = train_data\n",
    "import shap; shap.initjs(); explainer = shap.TreeExplainer(best_model); shap_values = explainer(x); sum_shap_values = explainer.shap_values(x)\n",
    "print(x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fdc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- SHAP -------\n",
    "import os\n",
    "if not os.path.exists(os.path.join(dataDir,\"waterfallplot\")):\n",
    "    os.makedirs(os.path.join(dataDir,\"waterfallplot\"))\n",
    "for i in range(0, int(x.shape[0]/10), 1):\n",
    "    shap_values = explainer(x)\n",
    "    shap_values.values = np.round(shap_values.values,3)\n",
    "    shap_values.base_values = np.round(shap_values.base_values,3)\n",
    "    shap_values.data = np.round(shap_values.data,3)\n",
    "    PP = i\n",
    "    model_p = round(best_model.predict_proba(x)[PP, 1] ,3)\n",
    "    print(PP, y[i], model_p)\n",
    "    shap.initjs()\n",
    "    plt.figure(figsize=(6,6))\n",
    "    shap.plots.waterfall(shap_values[PP], show = False, max_display = 10)\n",
    "    plt.savefig(os.path.join(os.path.join(dataDir,'waterfallplot'), 'SHAP_ID={},Lable={},probably={}.pdf'.format(str(data.iloc[:,0][PP]),str(y[PP]),str(model_p))), dpi=300,bbox_inches = 'tight',pad_inches=0.1) # DT\n",
    "    print(model_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39708934",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(dataDir,\"foreplot\")):\n",
    "    os.makedirs(os.path.join(dataDir,\"foreplot\"))\n",
    "    print(os.path.join(dataDir,\"foreplot\"))\n",
    "for i in range(0, 40, 1):\n",
    "    shap_values = explainer(round(x, 3))\n",
    "    PP = i\n",
    "    model_p = round(best_model.predict_proba(x)[PP, 1], 3)\n",
    "    print(data.iloc[PP, 0], y[PP], model_p)\n",
    "    shap.initjs()\n",
    "    shap.plots.force(explainer.expected_value,shap_values.values[PP],feature_names=list(x.columns),matplotlib=True, show=False, text_rotation = 7)\n",
    "#     plt.savefig(os.path.join(os.path.join(dataDir,\"foreplot\"), \"ID = {}, label = {}, p = {}.tiff\".format(val_data.iloc[PP, 0], y_val[PP], str(model_p))), dpi=50,bbox_inches = 'tight')\n",
    "    plt.savefig(os.path.join(os.path.join(dataDir,\"foreplot\"), \"{}, p = {}.pdf\".format(str(PP + 1), str(model_p))), dpi=300,bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thynet",
   "language": "python",
   "name": "thynet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
